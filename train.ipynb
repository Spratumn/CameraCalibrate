{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOU9M0m8RdUrVMCBZLnygPh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Spratumn/CameraCalibrate/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmTp_7dPwYrC",
        "colab_type": "text"
      },
      "source": [
        "加载Google云盘"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGlUHW1ZwPhP",
        "colab_type": "code",
        "outputId": "d3b66d3a-6c6a-4b24-89e2-b3e8fc24827a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "import os  # file path\n",
        "print(os.listdir(os.curdir))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "['.config', 'drive', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjKwnlyayFsu",
        "colab_type": "text"
      },
      "source": [
        "import pakages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJl66rvkyGcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from imgaug import augmenters as iaa\n",
        "import cv2 as cv\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3xlrptdzsr2",
        "colab_type": "text"
      },
      "source": [
        "配置信息"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt2QxXSX4uwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config():\n",
        "    # model config\n",
        "    CLASS_NUM = 8\n",
        "    \n",
        "    # deeplabv3p\n",
        "    ASPP_OUT_CHANNEL = 256\n",
        "    SHORTCUT_CHANNEL = 48\n",
        "    \n",
        "    # train config\n",
        "    MODEL = 'deeplabv3+' # 'unet','deeplabv3+'\n",
        "    TRAIN_NUMBER = 5 # 1,2,3,4,5,6,7,8,9,10\n",
        "    EPOCHS = 2  # total->50\n",
        "    TRAIN_BATCH_SIZE = 8\n",
        "    EVAL_BATCH_SIZE = 4\n",
        "    WEIGHT_DECAY = 1.0e-4\n",
        "    LR_LIST = [3e-4,2e-4,1e-4,5e-5,2e-5,1e-5,5e-6,2e-6,1e-6,5e-7]\n",
        "    BASE_LR = LR_LIST[TRAIN_NUMBER]\n",
        "    CSV_DIR = \"/content/drive/My Drive/LaneSeg/data_list\"\n",
        "    LOG_DIR = \"/content/drive/My Drive/LaneSeg/logs\"\n",
        "    PRE_TRAINED = True\n",
        "    PRE_TRAIN_WEIGHTS = 'laneNet_deeplabv3+_5th_epoch_02.pth.tar' # 'laneNet_{0}_{1}th.pth.tar'.format(MODEL,TRAIN_NUMBER-1)\n",
        "\n",
        "    # dataset config\n",
        "    IMAGE_SHAPE = (3,1710,3384)\n",
        "    CROP_SIZE = 699\n",
        "    RESIZE_SCALE = 3\n",
        "    # train_img_size->(3,337,1128)\n",
        "\n",
        "cfg = Config()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK37D2aPwoaT",
        "colab_type": "text"
      },
      "source": [
        "utils—label_process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dWV2FRhwyTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_encoder(mark_label):\n",
        "    \"\"\"mark label to train label\"\"\"\n",
        "\n",
        "    train_label = np.zeros((mark_label.shape[0], mark_label.shape[1]))\n",
        "\n",
        "    id_train = {0:[0, 249, 255, 213, 206, 207, 211, 208,216,215,218, 219,232, 202, 231,230,228,229,233,212,223],\n",
        "                1:[200, 204, 209], 2: [201,203], 3:[217], 4:[210], 5:[214],\n",
        "                6:[220,221,222,224,225,226], 7:[205,227,250]}\n",
        "    for i in range(8):\n",
        "        for item in id_train[i]:\n",
        "            train_label[mark_label == item] = i\n",
        "\n",
        "    return train_label\n",
        "\n",
        "\n",
        "def label_id_decoder(train_label):\n",
        "    \"\"\"train label to mark label for id\"\"\"\n",
        "    mark_label = np.zeros((train_label.shape[0], train_label.shape[1]), dtype='uint8')\n",
        "    # 0\n",
        "    mark_label[train_label == 0] = 0\n",
        "    # 1\n",
        "    mark_label[train_label == 1] = 204\n",
        "    # 2 \n",
        "    mark_label[train_label == 2] = 203\n",
        "    # 3\n",
        "    mark_label[train_label == 3] = 217\n",
        "    # 4\n",
        "    mark_label[train_label == 4] = 210\n",
        "    # 5\n",
        "    mark_label[train_label == 5] = 214\n",
        "    # 6\n",
        "    mark_label[train_label == 6] = 224\n",
        "    # 7\n",
        "    mark_label[train_label == 7] = 227\n",
        "\n",
        "    return mark_label\n",
        "\n",
        "\n",
        "def label_color_decoder(train_label):\n",
        "    \"\"\"train label to mark label for color map\"\"\"\n",
        "    mark_label = np.zeros((3, train_label.shape[0], train_label.shape[1]), dtype='uint8')\n",
        "    # 0\n",
        "    mark_label[0][train_label == 0] = 0\n",
        "    mark_label[1][train_label == 0] = 0\n",
        "    mark_label[2][train_label == 0] = 0\n",
        "    # 1\n",
        "    mark_label[0][train_label == 1] = 70\n",
        "    mark_label[1][train_label == 1] = 130\n",
        "    mark_label[2][train_label == 1] = 180\n",
        "    # 2\n",
        "    mark_label[0][train_label == 2] = 0\n",
        "    mark_label[1][train_label == 2] = 0\n",
        "    mark_label[2][train_label == 2] = 142\n",
        "    # 3\n",
        "    mark_label[0][train_label == 3] = 153\n",
        "    mark_label[1][train_label == 3] = 153\n",
        "    mark_label[2][train_label == 3] = 153\n",
        "    # 4\n",
        "    mark_label[0][train_label == 4] = 128\n",
        "    mark_label[1][train_label == 4] = 64\n",
        "    mark_label[2][train_label == 4] = 128\n",
        "    # 5\n",
        "    mark_label[0][train_label == 5] = 190\n",
        "    mark_label[1][train_label == 5] = 153\n",
        "    mark_label[2][train_label == 5] = 153\n",
        "    # 6\n",
        "    mark_label[0][train_label == 6] = 0\n",
        "    mark_label[1][train_label == 6] = 0\n",
        "    mark_label[2][train_label == 6] = 230\n",
        "    # 7\n",
        "    mark_label[0][train_label == 7] = 255\n",
        "    mark_label[1][train_label == 7] = 128\n",
        "    mark_label[2][train_label == 7] = 0\n",
        "\n",
        "    return mark_label\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0lFV-QSxIsc",
        "colab_type": "text"
      },
      "source": [
        "utils—image_process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KT1kUXJxOJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# attention: .jpg read by opencv,  .png read by PIL\n",
        "\n",
        "# crop the image to discard useless parts\n",
        "def crop_resize_data(image, label=None):\n",
        "    \"\"\"\n",
        "    Attention:\n",
        "    h,w, c = image.shape\n",
        "    cv2.resize(image,(w,h))\n",
        "    \"\"\"\n",
        "    roi_image = image[cfg.CROP_SIZE:, :]  # crop size\n",
        "    _,h,w = cfg.IMAGE_SHAPE\n",
        "    image_size = (int((h+1-cfg.CROP_SIZE)/cfg.RESIZE_SCALE),int(w/cfg.RESIZE_SCALE))\n",
        "    if label is not None:\n",
        "        roi_label = label[cfg.CROP_SIZE:, :]\n",
        "        train_image = cv.resize(roi_image, image_size, interpolation=cv.INTER_LINEAR)\n",
        "        train_label = cv.resize(roi_label, image_size, interpolation=cv.INTER_NEAREST)\n",
        "        return train_image, train_label\n",
        "    else:\n",
        "        train_image = cv.resize(roi_image, image_size, interpolation=cv.INTER_LINEAR)\n",
        "        return train_image\n",
        "\n",
        "\n",
        "class LaneSegTrainDataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "\n",
        "        super(LaneSegTrainDataset, self).__init__()\n",
        "        # read csv as data index\n",
        "        self.data_paths = pd.read_csv(os.path.join(cfg.CSV_DIR, csv_file), header=None,\n",
        "                                names=[\"image\",\"label\"])\n",
        "        self.image_paths = self.data_paths[\"image\"].values[1:]\n",
        "        self.label_paths = self.data_paths[\"label\"].values[1:]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.label_paths.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # read image and label by index\n",
        "        ori_image = cv.imread(self.image_paths[idx])\n",
        "        ori_label = np.array(Image.open(self.label_paths[idx]))\n",
        "        # crop and resize image and label\n",
        "        train_img, ori_label = crop_resize_data(ori_image, ori_label)\n",
        "        # Encode\n",
        "        train_label = label_encoder(ori_label)\n",
        "\n",
        "        sample = {'image': train_img,\n",
        "                'label': train_label}\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        \n",
        "        return sample\n",
        "\n",
        "class ToTensor(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample['image'], sample['label']\n",
        "\n",
        "        # swap color axis because\n",
        "        # opencv image: H x W x C\n",
        "        # torch image: C X W X H\n",
        "        image = image.transpose((2, 0, 1))\n",
        "\n",
        "        image_tensor = torch.from_numpy(image.astype(np.float32))\n",
        "        label_tensor = torch.from_numpy(label.astype(np.long))\n",
        "        return {'image': image_tensor,\n",
        "                'label': label_tensor}\n",
        "\n",
        "\n",
        "# imgaug Augmentation\n",
        "\n",
        "class ImageAug(object):\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample['image'], sample['label']\n",
        "        if np.random.uniform(0,1) > 0.5:\n",
        "            seq = iaa.Sequential([iaa.OneOf([\n",
        "                iaa.AdditiveGaussianNoise(scale=(0, 0.2 * 255)),\n",
        "                iaa.Sharpen(alpha=(0.1, 0.3), lightness=(0.7, 1.3)),\n",
        "                iaa.GaussianBlur(sigma=(0, 1.0))])])\n",
        "            image = seq.augment_image(image)\n",
        "        return {'image': image,\n",
        "                'label': label}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLv85PeKxYKK",
        "colab_type": "text"
      },
      "source": [
        "utils—loss and metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-C8TMODxgO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MySoftmaxCrossEntropyLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, nbclasses):\n",
        "        super(MySoftmaxCrossEntropyLoss, self).__init__()\n",
        "        self.nbclasses = nbclasses\n",
        "\n",
        "    def forward(self, inputs, target):\n",
        "        if inputs.dim() > 2:\n",
        "            inputs = inputs.view(inputs.size(0), inputs.size(1), -1)  # N,C,H,W => N,C,H*W\n",
        "            inputs = inputs.transpose(1, 2)  # N,C,H*W => N,H*W,C\n",
        "            inputs = inputs.contiguous().view(-1, self.nbclasses)  # N,H*W,C => N*H*W,C\n",
        "        target = target.view(-1)\n",
        "        return nn.CrossEntropyLoss(reduction=\"mean\")(inputs, target)\n",
        "\n",
        "\n",
        "def update_confusion_matrix(prediction, label, confus_matrix):\n",
        "    \"\"\"\n",
        "    prediction : [N, H, W]\n",
        "    label: [N, H, W]\n",
        "    \"\"\"\n",
        "    prediction = prediction.cpu().numpy()\n",
        "    label = label.cpu().numpy()\n",
        "    for i in range(8):\n",
        "        # label: Positive or Negative\n",
        "        label_p = label == i\n",
        "        label_n = label != i\n",
        "\n",
        "        # prediction: Positive or Negative\n",
        "        pred_p = prediction == i\n",
        "        pred_n = prediction != i\n",
        "\n",
        "        # label == Positive and prediction == Positive\n",
        "        tp = np.sum(label_p * pred_p)\n",
        "        # label == Negative and prediction == Negative \n",
        "        tn = np.sum(label_n * pred_n)\n",
        "        # label == Negative and prediction == Positive \n",
        "        fp = np.sum(label_n * pred_p)\n",
        "        # label == Positive and prediction == Negative \n",
        "        fn = np.sum(label_p * pred_n)\n",
        "        \n",
        "        confus_matrix[\"TP\"][i] += tp\n",
        "        confus_matrix[\"TN\"][i] += tn\n",
        "        confus_matrix[\"FP\"][i] += fp\n",
        "        confus_matrix[\"FN\"][i] += fn\n",
        "\n",
        "    return confus_matrix\n",
        "\n",
        "def compute_iou(confusion_matrix):\n",
        "    class_num = len(confusion_matrix[\"TP\"].keys())\n",
        "    ious = [0.0]*class_num\n",
        "\n",
        "    for i in range(class_num):\n",
        "        tp = confusion_matrix[\"TP\"][i]\n",
        "        fp = confusion_matrix[\"FP\"][i]\n",
        "        fn = confusion_matrix[\"FN\"][i]\n",
        "        ious[i] = tp/(tp+fp+fn)\n",
        "    return ious\n",
        "\n",
        "def compute_precision(confusion_matrix):\n",
        "    class_num = len(confusion_matrix[\"TP\"].keys())\n",
        "    precisions = [0.0]*class_num\n",
        "\n",
        "    for i in range(class_num):\n",
        "        tp = confusion_matrix[\"TP\"][i]\n",
        "        fp = confusion_matrix[\"FP\"][i]\n",
        "        precisions[i] = tp/(tp+fp)\n",
        "    return precisions\n",
        "\n",
        "def compute_recall(confusion_matrix):\n",
        "    class_num = len(confusion_matrix[\"TP\"].keys())\n",
        "    recalls = [0.0]*class_num\n",
        "\n",
        "    for i in range(class_num):\n",
        "        tp = confusion_matrix[\"TP\"][i]\n",
        "        fn = confusion_matrix[\"FN\"][i]\n",
        "        recalls[i] = tp/(tp+fn)\n",
        "    return recalls\n",
        "\n",
        "def compute_F1_score(precisions,recalls):\n",
        "    class_num = len(precisions)\n",
        "    f1_scores = [0.0]*class_num\n",
        "\n",
        "    for i in range(class_num):\n",
        "        f1_scores[i] = 2*precisions[i]*recalls[i]/(precisions[i]+recalls[i])\n",
        "    return f1_scores\n",
        "\n",
        "def compute_mean(score_list):\n",
        "    return np.mean(score_list[1:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS4Y4xT2yprb",
        "colab_type": "text"
      },
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ9UqaygysBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "SeparableConv2d(in_channel, out_channel)\n",
        "AtrousConv(in_channel, out_channel, dilation)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class SeparableConv2d(nn.Sequential):\n",
        "    \"\"\"\n",
        "    define separable Convolution Sequential\n",
        "    \"\"\"\n",
        "    def __init__(self,in_channel,out_channel\n",
        "                ,kernel_size=3,stride=1\n",
        "                ,padding=0,dilation=1, bias=False,act=0):\n",
        "        layers = []\n",
        "        layers.append(nn.Conv2d(in_channel,in_channel\n",
        "                            ,kernel_size=kernel_size\n",
        "                            ,stride=stride\n",
        "                            ,padding=padding\n",
        "                            ,dilation=dilation\n",
        "                            ,groups=in_channel\n",
        "                            ,bias=False))\n",
        "        layers.append(nn.BatchNorm2d(in_channel))\n",
        "        if act==1:\n",
        "            layers.append(nn.ReLU())\n",
        "        layers.append(nn.Conv2d(in_channel,out_channel\n",
        "                            ,kernel_size=1\n",
        "                            ,bias=False))\n",
        "        if act==1:\n",
        "            layers.append(nn.ReLU())\n",
        "        super(SeparableConv2d, self).__init__(*layers)\n",
        "\n",
        "\n",
        "class AtrousConv(nn.Sequential):\n",
        "    \"\"\"\n",
        "    define atrous Convolution Sequential with specific atrous_rate\n",
        "    kernel_size = 3  -->  padding = dilation\n",
        "    stride = 1\n",
        "    channels no change: out_channel = in_channel\n",
        "    out_size no change\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channel, out_channel, dilation):\n",
        "        layers = [\n",
        "            SeparableConv2d(in_channel, out_channel, kernel_size=3\n",
        "                    , padding=dilation, dilation=dilation, bias=False,act=0),\n",
        "            nn.BatchNorm2d(out_channel),\n",
        "            nn.ReLU()\n",
        "        ]\n",
        "        super(AtrousConv, self).__init__(*layers)\n",
        "\n",
        "\"\"\"\n",
        "ASPPConv(in_channel, out_channel, atrous_rates=[6,12,18])\n",
        "\"\"\"\n",
        "\n",
        "class ASPPPooling(nn.Sequential):\n",
        "    def __init__(self, in_channel, out_channel):\n",
        "        super(ASPPPooling, self).__init__(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(in_channel, out_channel, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channel),\n",
        "            nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        size = x.shape[-2:]\n",
        "        for mod in self:\n",
        "            x = mod(x)\n",
        "        return F.interpolate(x, size=size, mode='bilinear', align_corners=False)\n",
        "\n",
        "\n",
        "class ASPPConv(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, atrous_rates=[6,12,18]):\n",
        "        super(ASPPConv, self).__init__()\n",
        "        layers = []\n",
        "        layer_num = 2\n",
        "        # 1x1 conv part\n",
        "        layers.append(nn.Sequential(nn.Conv2d(in_channel, out_channel, 1, bias=False),\n",
        "                                    nn.BatchNorm2d(out_channel),\n",
        "                                    nn.ReLU()))\n",
        "        # atrous conv part\n",
        "        for atrous_rate in atrous_rates:\n",
        "            layers.append(AtrousConv(in_channel,out_channel,atrous_rate))\n",
        "            layer_num+=1\n",
        "        # pooling part\n",
        "        layers.append(ASPPPooling(in_channel, out_channel))\n",
        "        self.convs = nn.ModuleList(layers)\n",
        "\n",
        "        self.project = nn.Sequential(\n",
        "            nn.Conv2d(layer_num * out_channel, out_channel, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channel),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5))\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = []\n",
        "        for conv in self.convs:\n",
        "            res.append(conv(x))\n",
        "        res = torch.cat(res, dim=1)\n",
        "        return self.project(res)\n",
        "\n",
        "\n",
        "class XceptionBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    channel: no change\n",
        "    size: 1/2\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channel,out_channels):\n",
        "        super(XceptionBlock, self).__init__()\n",
        "        self.shortcut=nn.Conv2d(in_channel,out_channels[-1],\n",
        "                                kernel_size=1,\n",
        "                                stride=2,\n",
        "                                padding=0)\n",
        "        layers = []\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(SeparableConv2d(in_channel, out_channels[0],\n",
        "                                    kernel_size=3,\n",
        "                                    stride=1,\n",
        "                                    padding=1,\n",
        "                                    bias=False,\n",
        "                                    act=0))\n",
        "        for i in range(len(out_channels)-1):\n",
        "            layers.append(SeparableConv2d(out_channels[i], out_channels[i+1],\n",
        "                                        kernel_size=3,\n",
        "                                        stride=1,\n",
        "                                        padding=1,\n",
        "                                        bias=False,\n",
        "                                        act=0))\n",
        "        self.sep_conv1 = nn.Sequential(*layers)\n",
        "\n",
        "        self.sep_conv2 = SeparableConv2d(out_channels[-2], out_channels[-1],\n",
        "                                    kernel_size=3,\n",
        "                                    stride=2,\n",
        "                                    padding=1,\n",
        "                                    bias=False,\n",
        "                                    act=0)\n",
        "\n",
        "    def forward(self,x):\n",
        "        shortcut = self.shortcut(x)\n",
        "        sep_conv1 = self.sep_conv1(x)\n",
        "        sep_conv2 = self.sep_conv2(sep_conv1)\n",
        "        # print(shortcut.shape)\n",
        "        # print(sep_conv.shape)\n",
        "        return shortcut + sep_conv2, sep_conv1\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,short_channel):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.shortcut_conv = nn.Conv2d(256,short_channel\n",
        "                            ,kernel_size=3\n",
        "                            ,stride=1\n",
        "                            ,padding=1\n",
        "                            ,dilation=1\n",
        "                            ,bias=False)\n",
        "        layers = []\n",
        "        layers.append(SeparableConv2d(cfg.ASPP_OUT_CHANNEL+short_channel, 256,\n",
        "                                    kernel_size=3,\n",
        "                                    stride=1,\n",
        "                                    padding=1,\n",
        "                                    bias=False,\n",
        "                                    act=1))\n",
        "        layers.append(SeparableConv2d(256, 256,\n",
        "                                    kernel_size=3,\n",
        "                                    stride=1,\n",
        "                                    padding=1,\n",
        "                                    bias=False,\n",
        "                                    act=1))\n",
        "        self.decoder_conv = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self,encoder_feature,shortcut):\n",
        "        shortcut = self.shortcut_conv(shortcut)\n",
        "        encoder_feature = F.interpolate(encoder_feature,\n",
        "                                        size=(shortcut.shape[-2],shortcut.shape[-1]),\n",
        "                                        mode='bilinear',\n",
        "                                        align_corners=False)\n",
        "        encoder_feature = torch.cat((encoder_feature,shortcut),1)\n",
        "        decoder_feature = self.decoder_conv(encoder_feature)\n",
        "        return decoder_feature\n",
        "\n",
        "\n",
        "class Deeplabv3plus(nn.Module):\n",
        "    def __init__(self, in_channel=3, class_num=1000):\n",
        "        super(Deeplabv3plus, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channel,\n",
        "                            out_channels=32,\n",
        "                            kernel_size=3,\n",
        "                            stride=2,\n",
        "                            padding=1,\n",
        "                            bias=False)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32,\n",
        "                            out_channels=64,\n",
        "                            kernel_size=3,\n",
        "                            stride=1,\n",
        "                            padding=1,\n",
        "                            bias=False)\n",
        "        self.shortcut3 = XceptionBlock(64,[128,128,128])\n",
        "        self.shortcut4 = XceptionBlock(128,[256,256,256])\n",
        "        self.shortcut5 = XceptionBlock(256,[728,728,728])\n",
        "\n",
        "        middle_layers = []\n",
        "        for i in range(16):\n",
        "            middle_layers.append(SeparableConv2d(728, 728,\n",
        "                                    kernel_size=3,\n",
        "                                    stride=1,\n",
        "                                    padding=1,\n",
        "                                    bias=False,\n",
        "                                    act=0))\n",
        "        self.middle = nn.Sequential(*middle_layers)\n",
        "\n",
        "        self.shortcut7 = XceptionBlock(728,[728,1024,1024])\n",
        "        self.sep_conv8 = SeparableConv2d(1024, 1536,\n",
        "                                    kernel_size=3,\n",
        "                                    stride=1,\n",
        "                                    padding=1,\n",
        "                                    bias=False,\n",
        "                                    act=0)\n",
        "        self.sep_conv9 = SeparableConv2d(1536, 1536,\n",
        "                                    kernel_size=3,\n",
        "                                    stride=1,\n",
        "                                    padding=1,\n",
        "                                    bias=False,\n",
        "                                    act=0)\n",
        "        self.sep_conv10 = SeparableConv2d(1536, 2048,\n",
        "                                    kernel_size=3,\n",
        "                                    stride=1,\n",
        "                                    padding=1,\n",
        "                                    bias=False,\n",
        "                                    act=0)\n",
        "        \n",
        "        self.encoder = ASPPConv(2048,cfg.ASPP_OUT_CHANNEL)\n",
        "        \n",
        "        self.decoder = Decoder(short_channel=cfg.SHORTCUT_CHANNEL)\n",
        "        self.predictor = nn.Sequential(nn.Conv2d(256, class_num,\n",
        "                                                kernel_size=3,\n",
        "                                                stride=1,\n",
        "                                                padding=1,\n",
        "                                                bias=False))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        out_conv1 = self.conv1(x)\n",
        "        out_conv2 = self.conv2(out_conv1)\n",
        "        out_shortcut3,_ = self.shortcut3(out_conv2)\n",
        "        out_shortcut4, out_shortcut = self.shortcut4(out_shortcut3)\n",
        "        out_shortcut5,_ = self.shortcut5(out_shortcut4)\n",
        "        out_middle = self.middle(out_shortcut5)\n",
        "        out_shortcut7,_ = self.shortcut7(out_middle)\n",
        "        out_sep_conv8 = self.sep_conv8(out_shortcut7)\n",
        "        out_sep_conv9 = self.sep_conv9(out_sep_conv8)\n",
        "        out_sep_conv10 = self.sep_conv10(out_sep_conv9)\n",
        "\n",
        "        encoder_feature = self.encoder(out_sep_conv10)\n",
        "        decoder_feature = self.decoder(encoder_feature,out_shortcut)\n",
        "        logit = self.predictor(decoder_feature)\n",
        "        logit = F.interpolate(logit,\n",
        "                            size=(x.shape[-2],x.shape[-1]),\n",
        "                            mode='bilinear',\n",
        "                            align_corners=False)\n",
        "        return logit\n",
        "\n",
        "# unet\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    layers = []\n",
        "    layers.append(nn.Conv2d(in_planes, out_planes, \n",
        "                        kernel_size=3, padding=1, stride=stride))\n",
        "    layers.append(nn.BatchNorm2d(out_planes))\n",
        "    layers.append(nn.ReLU())\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution without padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride)\n",
        "\n",
        "def up_conv2x2(in_planes,out_planes):\n",
        "\n",
        "    return nn.ConvTranspose2d(in_planes,out_planes,kernel_size=2,stride=2)\n",
        "\n",
        "def max_pool2x2():\n",
        "    return nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "def match_size(src_tensor,dst_size):\n",
        "    return F.interpolate(src_tensor, size=dst_size, mode='bilinear', align_corners=False)\n",
        "\n",
        "class UNetv1(nn.Module):\n",
        "    def __init__(self,in_channel=3, class_num=1000):\n",
        "        super(UNetv1, self).__init__()\n",
        "        # downsample stage\n",
        "        self.conv_1 = nn.Sequential(conv3x3(in_channel,64),conv3x3(64,64))\n",
        "        self.conv_2 = nn.Sequential(conv3x3(64,128),conv3x3(128,128))\n",
        "        self.conv_3 = nn.Sequential(conv3x3(128,256),conv3x3(256,256))\n",
        "        self.conv_4 = nn.Sequential(conv3x3(256,512),conv3x3(512,512))\n",
        "        self.conv_5 = nn.Sequential(conv3x3(512,1024),conv3x3(1024,1024))\n",
        "        self.maxpool = max_pool2x2()\n",
        "        \n",
        "        # upsample stage\n",
        "        # up_conv_4 corresponds conv_4\n",
        "        self.up_conv_4 = nn.Sequential(up_conv2x2(1024,512))\n",
        "        # conv the cat(stage_4,up_conv_4) from 1024 to 512\n",
        "        self.conv_6 = nn.Sequential(conv3x3(1024,512),conv3x3(512,512))\n",
        "        # up_conv_3 corresponds conv_3\n",
        "        self.up_conv_3 = nn.Sequential(up_conv2x2(512,256))\n",
        "        # conv the cat(stage_3,up_conv_3) from 512 to 256\n",
        "        self.conv_7 = nn.Sequential(conv3x3(512,256),conv3x3(256,256))\n",
        "        # up_conv_2 corresponds conv_2\n",
        "        self.up_conv_2 = nn.Sequential(up_conv2x2(256,128))\n",
        "        # conv the cat(stage_2,up_conv_2) from 256 to 128\n",
        "        self.conv_8 = nn.Sequential(conv3x3(256,128),conv3x3(128,128))\n",
        "        # up_conv_1 corresponds conv_1\n",
        "        self.up_conv_1 = nn.Sequential(up_conv2x2(128,64))\n",
        "        # conv the cat(stage_1,up_conv_1) from 128 to 64\n",
        "        self.conv_9 = nn.Sequential(conv3x3(128,64),conv3x3(64,64))\n",
        "        # output\n",
        "        self.result = conv1x1(64,class_num)\n",
        "\n",
        "    def forward(self,x):\n",
        "        # get 4 stage conv output\n",
        "        stage_1 = self.conv_1(x)\n",
        "        size_1 = stage_1.shape[-2:]\n",
        "        # print(size_1)\n",
        "        stage_2 = self.conv_2(self.maxpool(stage_1))\n",
        "        size_2 = stage_2.shape[-2:]\n",
        "        # print(size_2)\n",
        "        stage_3 = self.conv_3(self.maxpool(stage_2))\n",
        "        size_3 = stage_3.shape[-2:]\n",
        "        # print(size_3)\n",
        "        stage_4 = self.conv_4(self.maxpool(stage_3))\n",
        "        size_4 = stage_4.shape[-2:]\n",
        "        # print(size_4)\n",
        "\n",
        "        # get up_conv_4 and concat with stage_4\n",
        "        up_in_4 = self.conv_5(self.maxpool(stage_4))\n",
        "        up_stage_4 = self.up_conv_4(up_in_4)\n",
        "        up_stage_4 = match_size(up_stage_4,size_4)\n",
        "        up_stage_4 = torch.cat((stage_4,up_stage_4),1)\n",
        "        # get up_conv_3 and concat with stage_3\n",
        "        up_in_3 = self.conv_6(up_stage_4)\n",
        "        up_stage_3 = self.up_conv_3(up_in_3)\n",
        "        up_stage_3 = match_size(up_stage_3,size_3)\n",
        "        up_stage_3 = torch.cat((stage_3,up_stage_3),1)\n",
        "        # get up_conv_2 and concat with stage_2\n",
        "        up_in_2 = self.conv_7(up_stage_3)\n",
        "        up_stage_2 = self.up_conv_2(up_in_2)\n",
        "        up_stage_2 = match_size(up_stage_2,size_2)\n",
        "        up_stage_2 = torch.cat((stage_2,up_stage_2),1)\n",
        "        # get up_conv_1 and concat with stage_1\n",
        "        up_in_1 = self.conv_8(up_stage_2)\n",
        "        up_stage_1 = self.up_conv_1(up_in_1)\n",
        "        up_stage_1 = match_size(up_stage_1,size_1)\n",
        "        up_stage_1 = torch.cat((stage_1,up_stage_1),1)\n",
        "\n",
        "        # last conv to channel 2\n",
        "        out = self.conv_9(up_stage_1)\n",
        "        # result\n",
        "        out = self.result(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lELYcvfzIVw",
        "colab_type": "text"
      },
      "source": [
        "batch train val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHcMuRomzQEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(net, epoch, dataLoader, optimizer, criterion, train_log):\n",
        "    # set to train \n",
        "    net.train()\n",
        "    total_loss = 0.0\n",
        "    dataprocess = tqdm(dataLoader)\n",
        "    \n",
        "    for batch_item in dataprocess:\n",
        "        # get batch data\n",
        "        batch_image, batch_label = batch_item['image'], batch_item['label']\n",
        "        if torch.cuda.is_available():\n",
        "            batch_image, batch_label = batch_image.cuda(), batch_label.cuda()\n",
        "        # zero the gradient buffers\n",
        "        optimizer.zero_grad()\n",
        "        # forward to get output\n",
        "        batch_out = net(batch_image)\n",
        "        # compute loss\n",
        "        batch_loss = criterion(batch_out, batch_label)\n",
        "        total_loss += batch_loss.item()\n",
        "        # auto backward\n",
        "        batch_loss.backward()\n",
        "        # update weights\n",
        "        optimizer.step()\n",
        "        # print batch result\n",
        "        dataprocess.set_description_str(\"epoch:{}\".format(epoch))\n",
        "        dataprocess.set_postfix_str(\"batch_loss:{:.4f}\".format(batch_loss.item()))\n",
        "\n",
        "    # when opoch finished write to log file\n",
        "    # log_title = 'epoch,average loss'\n",
        "    log_string = \"{},{:.4f} \\n\".format(epoch, total_loss / len(dataLoader))\n",
        "    train_log.write(log_string)\n",
        "    train_log.flush()\n",
        "\n",
        "\n",
        "def eval_epoch(net, epoch, dataLoader, eval_log):\n",
        "    # set to eval \n",
        "    net.eval()\n",
        "    total_loss = 0.0\n",
        "    dataprocess = tqdm(dataLoader)\n",
        "    # init confusion matrix with all zeros\n",
        "    confusion_matrix = {\"TP\": {i:0 for i in range(8)},\n",
        "                        \"TN\": {i:0 for i in range(8)},\n",
        "                        \"FP\": {i:0 for i in range(8)},\n",
        "                        \"FN\": {i:0 for i in range(8)}}\n",
        "\n",
        "    for batch_item in dataprocess:\n",
        "        # get batch data\n",
        "        batch_image, batch_label = batch_item['image'], batch_item['label']\n",
        "        if torch.cuda.is_available():\n",
        "            batch_image, batch_label = batch_image.cuda(), batch_label.cuda()\n",
        "        # forward to get output\n",
        "        batch_out = net(batch_image)\n",
        "        # compute loss\n",
        "        batch_loss = MySoftmaxCrossEntropyLoss(cfg.CLASS_NUM)(batch_out, batch_label)\n",
        "        total_loss += batch_loss.detach().item()\n",
        "        \n",
        "        # get prediction,shape and values type same as batch_label\n",
        "\n",
        "        # softmax: (1,0,0)->(0.89,0.06,0.05)\n",
        "        # argmax: (0.89,0.06,0.05)->return index 0 \n",
        "        pred = torch.argmax(F.softmax(batch_out, dim=1), dim=1)\n",
        "        # compute confusion matrix\n",
        "        confusion_matrix = update_confusion_matrix(pred, batch_label, confusion_matrix)\n",
        "        # print batch result\n",
        "        dataprocess.set_description_str(\"epoch:{}\".format(epoch))\n",
        "        dataprocess.set_postfix_str(\"batch_loss:{:.4f}\".format(batch_loss))\n",
        "\n",
        "    eval_loss = total_loss / len(dataLoader)\n",
        "    \n",
        "    # compute metric\n",
        "    epoch_ious = compute_iou(confusion_matrix)\n",
        "    epoch_m_iou = compute_mean(epoch_ious)\n",
        "    epoch_precisions = compute_precision(confusion_matrix)\n",
        "    epoch_m_precision = compute_mean(epoch_precisions)\n",
        "    epoch_recalls = compute_recall(confusion_matrix)\n",
        "    epoch_m_recall = compute_mean(epoch_recalls)\n",
        "    \n",
        "    # print eval iou every epoch\n",
        "    print('mean iou: {} \\n'.format(epoch_m_iou))\n",
        "    for i in range(8):\n",
        "        print_string = \"iou_class_{} : {:.4f}\\n\".format(i, epoch_ious[i])\n",
        "        print(print_string)\n",
        "    \n",
        "    # make log string\n",
        "    log_values = [epoch,eval_loss,epoch_m_iou]+epoch_ious\n",
        "    log_values += [epoch_m_precision]+epoch_precisions+[epoch_m_recall]+epoch_recalls\n",
        "    log_values = [str(v) for v in log_values]\n",
        "    log_string = ','.join(log_values)\n",
        "    eval_log.write(log_string+'\\n')\n",
        "    eval_log.flush()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si6qkJDPz6Cv",
        "colab_type": "text"
      },
      "source": [
        "main train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcr785Nsz6Vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using multiprocesss to load data when cuda is available \n",
        "kwargs = {'num_workers': 4, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
        "\n",
        "# set image augment\n",
        "augments = [ImageAug(),ToTensor()]\n",
        "\n",
        "# get dataset and iterable dataloader\n",
        "train_dataset = LaneSegTrainDataset(\"train.csv\",transform=transforms.Compose(augments))\n",
        "train_data_batch = DataLoader(train_dataset, batch_size=cfg.TRAIN_BATCH_SIZE, \n",
        "                              shuffle=True, drop_last=True, **kwargs)\n",
        "\n",
        "eval_dataset = LaneSegTrainDataset(\"eval.csv\",transform=transforms.Compose([ToTensor()]))\n",
        "eval_data_batch = DataLoader(eval_dataset, batch_size=cfg.EVAL_BATCH_SIZE, \n",
        "                             shuffle=False, drop_last=False, **kwargs)\n",
        "\n",
        "# define model\n",
        "\n",
        "if cfg.MODEL == 'deeplabv3+':\n",
        "    net = Deeplabv3plus(class_num=cfg.CLASS_NUM)\n",
        "    \n",
        "elif cfg.MODEL == 'unet':\n",
        "    net = UNetv1(class_num=cfg.CLASS_NUM)\n",
        "else:\n",
        "    net = UNetv1(class_num=cfg.CLASS_NUM)\n",
        "# load pretrained weights\n",
        "if cfg.PRE_TRAINED:\n",
        "    checkpoint = torch.load(os.path.join(cfg.LOG_DIR,cfg.PRE_TRAIN_WEIGHTS))\n",
        "    net.load_state_dict(checkpoint['state_dict'])\n",
        "# use cuda if available\n",
        "if torch.cuda.is_available():\n",
        "    net = net.cuda()\n",
        "\n",
        "# define optimizer\n",
        "# optimizer = torch.optim.SGD(net.parameters(), lr=cfg.BASE_LR, momentum=0.9, weight_decay=cfg.WEIGHT_DECAY)\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=cfg.BASE_LR, weight_decay=cfg.WEIGHT_DECAY)\n",
        "criterion = MySoftmaxCrossEntropyLoss(cfg.CLASS_NUM)\n",
        "\n",
        "# define log file\n",
        "train_log = open(os.path.join(cfg.LOG_DIR, \"train_log_{0}_{1}th.csv\".format(cfg.MODEL,cfg.TRAIN_NUMBER)), 'w')\n",
        "train_log_title = \"epoch,average loss\\n\"\n",
        "train_log.write(train_log_title)\n",
        "train_log.flush()\n",
        "eval_log = open(os.path.join(cfg.LOG_DIR, \"eval_log_{0}_{1}th.csv\".format(cfg.MODEL,cfg.TRAIN_NUMBER)), 'w')\n",
        "eval_log_title = \"epoch,average_loss,\\\n",
        "                 mean_iou,\\\n",
        "                 iou_0,iou_1,iou_2,iou_3,iou_4,iou_5,iou_6,iou_7,\\\n",
        "                 mean_precision,\\\n",
        "                 precision_0,precision_1,precision_2,precision_3,precision_4,precision_5,precision_6,precision_7,\\\n",
        "                 mean_recall,\\\n",
        "                 recall_0,recall_1,recall_2,recall_3,recall_4,recall_5,recall_6,recall_7\\n\"\n",
        "eval_log.write(eval_log_title)\n",
        "eval_log.flush()\n",
        "# train and test epoch by epoch\n",
        "for epoch in range(cfg.EPOCHS):\n",
        "    train_epoch(net, epoch, train_data_batch, optimizer, criterion, train_log)\n",
        "    torch.save({'state_dict': net.state_dict()},\n",
        "                   os.path.join(cfg.LOG_DIR,\n",
        "                                \"laneNet_{0}_{1}th_epoch_{2}.pth.tar\".format(cfg.MODEL,cfg.TRAIN_NUMBER,epoch)))\n",
        "    eval_epoch(net, epoch, eval_data_batch, eval_log)\n",
        "        \n",
        "    \n",
        "train_log.close()\n",
        "eval_log.close()\n",
        "torch.save({'state_dict': net.state_dict()},\n",
        "           os.path.join(cfg.LOG_DIR, \n",
        "                        \"laneNet_{0}_{1}th.pth.tar\".format(cfg.MODEL,cfg.TRAIN_NUMBER)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}